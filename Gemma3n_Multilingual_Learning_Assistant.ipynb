{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f6d00d6",
   "metadata": {},
   "source": [
    "Block 1: Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "334fc1fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ All libraries imported successfully!\n",
      "PyTorch version: 2.7.1\n",
      "CUDA available: False\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Setup and Imports\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Tuple, Optional, Any\n",
    "from pathlib import Path\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Core ML libraries\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import google.generativeai as genai\n",
    "import openai\n",
    "\n",
    "# Jupyter widgets\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML, clear_output\n",
    "from IPython.display import Audio, Image\n",
    "\n",
    "# Environment and utilities\n",
    "from dotenv import load_dotenv\n",
    "import requests\n",
    "from tqdm.notebook import tqdm\n",
    "import faiss\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv('config.env')\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully!\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f52056",
   "metadata": {},
   "source": [
    "Block 2: Configuration and Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "145b729c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Configuration loaded successfully!\n",
      "Supported languages: 16\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Configuration and Constants\n",
    "class Config:\n",
    "    \"\"\"Configuration class for the multilingual learning assistant\"\"\"\n",
    "    \n",
    "    # API Keys\n",
    "    HUGGINGFACE_TOKEN = os.getenv('HUGGINGFACE_API_TOKEN')\n",
    "    GOOGLE_AI_KEY = os.getenv('GOOGLE_AI_API_KEY')\n",
    "    OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "    \n",
    "    # File paths\n",
    "    FAISS_INDEX_PATH = os.getenv('FAISS_INDEX_PATH', './data/word_embeddings.faiss')\n",
    "    METADATA_PATH = os.getenv('METADATA_PATH', './data/learned_words.json')\n",
    "    \n",
    "    # Model configurations (Updated)\n",
    "    DEFAULT_TRANSLATION_MODEL = \"Helsinki-NLP/opus-mt-hi-en\"  # Smaller, reliable model\n",
    "    \n",
    "    # Language mappings\n",
    "    LANGUAGE_MAPPINGS = {\n",
    "        'hindi': {'code': 'hi', 'name': 'Hindi', 'script': 'Devanagari'},\n",
    "        'tamil': {'code': 'ta', 'name': 'Tamil', 'script': 'Tamil'},\n",
    "        'bengali': {'code': 'bn', 'name': 'Bengali', 'script': 'Bengali'},\n",
    "        'kannada': {'code': 'kn', 'name': 'Kannada', 'script': 'Kannada'},\n",
    "        'telugu': {'code': 'te', 'name': 'Telugu', 'script': 'Telugu'},\n",
    "        'gujarati': {'code': 'gu', 'name': 'Gujarati', 'script': 'Gujarati'},\n",
    "        'marathi': {'code': 'mr', 'name': 'Marathi', 'script': 'Devanagari'},\n",
    "        'punjabi': {'code': 'pa', 'name': 'Punjabi', 'script': 'Gurmukhi'},\n",
    "        'urdu': {'code': 'ur', 'name': 'Urdu', 'script': 'Perso-Arabic'},\n",
    "        'malayalam': {'code': 'ml', 'name': 'Malayalam', 'script': 'Malayalam'},\n",
    "        'odia': {'code': 'or', 'name': 'Odia', 'script': 'Odia'},\n",
    "        'assamese': {'code': 'as', 'name': 'Assamese', 'script': 'Bengali'},\n",
    "        'manipuri': {'code': 'mni', 'name': 'Manipuri', 'script': 'Bengali'},\n",
    "        'kashmiri': {'code': 'ks', 'name': 'Kashmiri', 'script': 'Perso-Arabic'},\n",
    "        'konkani': {'code': 'kok', 'name': 'Konkani', 'script': 'Devanagari'},\n",
    "        'sanskrit': {'code': 'sa', 'name': 'Sanskrit', 'script': 'Devanagari'}\n",
    "    }\n",
    "    \n",
    "    # Create data directory\n",
    "    @classmethod\n",
    "    def setup_directories(cls):\n",
    "        Path('./data').mkdir(exist_ok=True)\n",
    "        Path('./logs').mkdir(exist_ok=True)\n",
    "\n",
    "# Initialize configuration\n",
    "Config.setup_directories()\n",
    "print(\"‚úÖ Configuration loaded successfully!\")\n",
    "print(f\"Supported languages: {len(Config.LANGUAGE_MAPPINGS)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2665ab71",
   "metadata": {},
   "source": [
    "Block 3: Translation Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "475fbd43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Initializing translation models...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Translator loaded: Helsinki-NLP/opus-mt-hi-en\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Translation Service\n",
    "class TranslationService:\n",
    "    \"\"\"Handles translation between Indian languages and English\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.translator = None\n",
    "        self._initialize_translators()\n",
    "    \n",
    "    def _initialize_translators(self):\n",
    "        \"\"\"Initialize translation models with error handling\"\"\"\n",
    "        try:\n",
    "            print(\"üîÑ Initializing translation models...\")\n",
    "            \n",
    "            # Use a smaller, more reliable model\n",
    "            model_name = \"Helsinki-NLP/opus-mt-hi-en\"  # Hindi to English (smaller, reliable)\n",
    "            \n",
    "            if Config.HUGGINGFACE_TOKEN:\n",
    "                self.translator = pipeline(\n",
    "                    \"translation\",\n",
    "                    model=model_name,\n",
    "                    token=Config.HUGGINGFACE_TOKEN\n",
    "                )\n",
    "                print(f\"‚úÖ Translator loaded: {model_name}\")\n",
    "            else:\n",
    "                print(\"‚ö†Ô∏è No Hugging Face token provided, trying without token\")\n",
    "                self.translator = pipeline(\n",
    "                    \"translation\",\n",
    "                    model=model_name\n",
    "                )\n",
    "                print(f\"‚úÖ Translator loaded: {model_name}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error loading translator: {e}\")\n",
    "            self.translator = None\n",
    "    \n",
    "    def translate_to_english(self, text: str, source_language: str) -> Dict[str, Any]:\n",
    "        \"\"\"Translate text to English with metadata\"\"\"\n",
    "        result = {\n",
    "            'original_text': text,\n",
    "            'source_language': source_language,\n",
    "            'translated_text': 'unknown',\n",
    "            'confidence': 0.0,\n",
    "            'model_used': 'none',\n",
    "            'error': None\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            if self.translator:\n",
    "                translation = self.translator(text)\n",
    "                result['translated_text'] = translation[0]['translation_text']\n",
    "                result['confidence'] = 0.7  # Lower confidence since it's not language-specific\n",
    "                result['model_used'] = 'Helsinki-NLP/opus-mt-hi-en'\n",
    "            else:\n",
    "                result['error'] = \"No translation models available\"\n",
    "                \n",
    "        except Exception as e:\n",
    "            result['error'] = str(e)\n",
    "            print(f\"‚ùå Translation error: {e}\")\n",
    "        \n",
    "        return result\n",
    "\n",
    "# Initialize translation service\n",
    "translation_service = TranslationService()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c073fe1",
   "metadata": {},
   "source": [
    "Block 4: Gemma 3n Integration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "96842715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gemma 3n model initialized successfully!\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Gemma 3n Integration (Fixed)\n",
    "class GemmaService:\n",
    "    \"\"\"Handles interactions with Gemma 3n model\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "        self._initialize_gemma()\n",
    "    \n",
    "    def _initialize_gemma(self):\n",
    "        \"\"\"Initialize Gemma 3n model\"\"\"\n",
    "        try:\n",
    "            if Config.GOOGLE_AI_KEY:\n",
    "                genai.configure(api_key=Config.GOOGLE_AI_KEY)\n",
    "                # Use the correct model name from the available list\n",
    "                self.model = genai.GenerativeModel('gemma-3n-e4b-it')  # Using the 4B model\n",
    "                print(\"Gemma 3n model initialized successfully!\")\n",
    "            else:\n",
    "                print(\"No Google AI API key provided\")\n",
    "                self.model = None\n",
    "        except Exception as e:\n",
    "            print(f\"Error initializing Gemma: {e}\")\n",
    "            self.model = None\n",
    "    \n",
    "    def get_word_explanation(self, word: str, language: str, english_translation: str) -> Dict[str, Any]:\n",
    "        \"\"\"Get comprehensive explanation from Gemma\"\"\"\n",
    "        if not self.model:\n",
    "            return {\n",
    "                'explanation': 'Gemma model not available',\n",
    "                'pronunciation': 'unknown',\n",
    "                'usage_examples': [],\n",
    "                'cultural_context': 'unknown',\n",
    "                'error': 'Model not initialized'\n",
    "            }\n",
    "        \n",
    "        try:\n",
    "            prompt = f\"\"\"\n",
    "            Please provide a comprehensive explanation for the word \"{word}\" from {language} language.\n",
    "            \n",
    "            English translation: {english_translation}\n",
    "            \n",
    "            Please provide:\n",
    "            1. Pronunciation guide (with IPA if possible)\n",
    "            2. Usage examples in sentences\n",
    "            3. Cultural context and significance\n",
    "            4. Related words or synonyms\n",
    "            \n",
    "            Format your response as JSON with these keys:\n",
    "            - pronunciation\n",
    "            - usage_examples (list)\n",
    "            - cultural_context\n",
    "            - related_words (list)\n",
    "            \"\"\"\n",
    "            \n",
    "            response = self.model.generate_content(prompt)\n",
    "            \n",
    "            # Try to parse JSON response\n",
    "            try:\n",
    "                import json\n",
    "                explanation_data = json.loads(response.text)\n",
    "                return {\n",
    "                    'explanation': response.text,\n",
    "                    'pronunciation': explanation_data.get('pronunciation', 'unknown'),\n",
    "                    'usage_examples': explanation_data.get('usage_examples', []),\n",
    "                    'cultural_context': explanation_data.get('cultural_context', 'unknown'),\n",
    "                    'related_words': explanation_data.get('related_words', []),\n",
    "                    'error': None\n",
    "                }\n",
    "            except:\n",
    "                # If JSON parsing fails, return raw response\n",
    "                return {\n",
    "                    'explanation': response.text,\n",
    "                    'pronunciation': 'unknown',\n",
    "                    'usage_examples': [],\n",
    "                    'cultural_context': 'unknown',\n",
    "                    'related_words': [],\n",
    "                    'error': None\n",
    "                }\n",
    "                \n",
    "        except Exception as e:\n",
    "            return {\n",
    "                'explanation': 'Error generating explanation',\n",
    "                'pronunciation': 'unknown',\n",
    "                'usage_examples': [],\n",
    "                'cultural_context': 'unknown',\n",
    "                'related_words': [],\n",
    "                'error': str(e)\n",
    "            }\n",
    "\n",
    "# Initialize Gemma service\n",
    "gemma_service = GemmaService()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0713dab",
   "metadata": {},
   "source": [
    "Block 5: FAISS Storage Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d1bb2d7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Embedding model loaded\n",
      "‚úÖ Loaded existing FAISS index with 14 vectors\n",
      "‚úÖ Loaded 14 word entries\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: FAISS Storage Service\n",
    "class WordStorageService:\n",
    "    \"\"\"Handles storage and retrieval of learned words using FAISS\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.index = None\n",
    "        self.metadata = []\n",
    "        self.embedding_model = None\n",
    "        self._initialize_storage()\n",
    "    \n",
    "    def _initialize_storage(self):\n",
    "        \"\"\"Initialize FAISS index and embedding model\"\"\"\n",
    "        try:\n",
    "            # Load embedding model\n",
    "            self.embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "            print(\"‚úÖ Embedding model loaded\")\n",
    "            \n",
    "            # Try to load existing index\n",
    "            if os.path.exists(Config.FAISS_INDEX_PATH):\n",
    "                self.index = faiss.read_index(Config.FAISS_INDEX_PATH)\n",
    "                print(f\"‚úÖ Loaded existing FAISS index with {self.index.ntotal} vectors\")\n",
    "            else:\n",
    "                # Create new index\n",
    "                dimension = self.embedding_model.get_sentence_embedding_dimension()\n",
    "                self.index = faiss.IndexFlatL2(dimension)\n",
    "                print(f\"‚úÖ Created new FAISS index with dimension {dimension}\")\n",
    "            \n",
    "            # Load metadata\n",
    "            self._load_metadata()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error initializing storage: {e}\")\n",
    "    \n",
    "    def _load_metadata(self):\n",
    "        \"\"\"Load word metadata from JSON file\"\"\"\n",
    "        try:\n",
    "            if os.path.exists(Config.METADATA_PATH):\n",
    "                with open(Config.METADATA_PATH, 'r', encoding='utf-8') as f:\n",
    "                    self.metadata = json.load(f)\n",
    "                print(f\"‚úÖ Loaded {len(self.metadata)} word entries\")\n",
    "            else:\n",
    "                self.metadata = []\n",
    "                print(\"‚úÖ No existing metadata found, starting fresh\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error loading metadata: {e}\")\n",
    "            self.metadata = []\n",
    "    \n",
    "    def _save_metadata(self):\n",
    "        \"\"\"Save word metadata to JSON file\"\"\"\n",
    "        try:\n",
    "            with open(Config.METADATA_PATH, 'w', encoding='utf-8') as f:\n",
    "                json.dump(self.metadata, f, ensure_ascii=False, indent=2)\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error saving metadata: {e}\")\n",
    "    \n",
    "    def add_word(self, word_data: Dict[str, Any]) -> bool:\n",
    "        \"\"\"Add a new word to storage\"\"\"\n",
    "        try:\n",
    "            # Create embedding\n",
    "            text_for_embedding = f\"{word_data['original_word']} {word_data['english_translation']} {word_data['language']}\"\n",
    "            embedding = self.embedding_model.encode([text_for_embedding])\n",
    "            \n",
    "            # Add to FAISS index\n",
    "            self.index.add(embedding)\n",
    "            \n",
    "            # Add metadata\n",
    "            word_entry = {\n",
    "                'id': len(self.metadata),\n",
    "                'original_word': word_data['original_word'],\n",
    "                'english_translation': word_data['english_translation'],\n",
    "                'language': word_data['language'],\n",
    "                'pronunciation': word_data.get('pronunciation', 'unknown'),\n",
    "                'usage_examples': word_data.get('usage_examples', []),\n",
    "                'cultural_context': word_data.get('cultural_context', 'unknown'),\n",
    "                'related_words': word_data.get('related_words', []),\n",
    "                'date_added': datetime.now().isoformat(),\n",
    "                'translation_confidence': word_data.get('translation_confidence', 0.0),\n",
    "                'model_used': word_data.get('model_used', 'unknown')\n",
    "            }\n",
    "            \n",
    "            self.metadata.append(word_entry)\n",
    "            \n",
    "            # Save to disk\n",
    "            faiss.write_index(self.index, Config.FAISS_INDEX_PATH)\n",
    "            self._save_metadata()\n",
    "            \n",
    "            print(f\"‚úÖ Added word: {word_data['original_word']} ({word_data['language']})\")\n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error adding word: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def search_words(self, query: str, k: int = 5) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Search for similar words\"\"\"\n",
    "        try:\n",
    "            query_embedding = self.embedding_model.encode([query])\n",
    "            distances, indices = self.index.search(query_embedding, min(k, len(self.metadata)))\n",
    "            \n",
    "            results = []\n",
    "            for i, idx in enumerate(indices[0]):\n",
    "                if idx < len(self.metadata):\n",
    "                    result = self.metadata[idx].copy()\n",
    "                    result['similarity_score'] = 1.0 / (1.0 + distances[0][i])\n",
    "                    results.append(result)\n",
    "            \n",
    "            return results\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error searching words: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def get_all_words(self) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Get all stored words\"\"\"\n",
    "        return self.metadata.copy()\n",
    "    \n",
    "    def get_words_by_language(self, language: str) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Get words by specific language\"\"\"\n",
    "        return [word for word in self.metadata if word['language'].lower() == language.lower()]\n",
    "    \n",
    "    def get_random_words_for_quiz(self, count: int = 5, languages: List[str] = None) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Get random words for quiz mode\"\"\"\n",
    "        import random\n",
    "        \n",
    "        if languages:\n",
    "            available_words = [word for word in self.metadata if word['language'].lower() in [lang.lower() for lang in languages]]\n",
    "        else:\n",
    "            available_words = self.metadata\n",
    "        \n",
    "        if len(available_words) < count:\n",
    "            return available_words\n",
    "        \n",
    "        return random.sample(available_words, count)\n",
    "\n",
    "# Initialize storage service\n",
    "storage_service = WordStorageService()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8810ad2f",
   "metadata": {},
   "source": [
    "Block 6: Main Learning Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7089d3dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <script>\n",
       "        document.getElementById('unicode-input').addEventListener('input', function() {\n",
       "            window.unicodeInputValue = this.value;\n",
       "        });\n",
       "        </script>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cell 6: Main Learning Interface\n",
    "class MultilingualLearningInterface:\n",
    "    \"\"\"Main interface for the multilingual learning assistant\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.setup_widgets()\n",
    "        self.setup_layout()\n",
    "    \n",
    "    def setup_widgets(self):\n",
    "        \"\"\"Setup all interactive widgets with enhanced Unicode support\"\"\"\n",
    "        \n",
    "        # Language selection\n",
    "        self.language_dropdown = widgets.Dropdown(\n",
    "            options=[(f\"{lang_info['name']} ({lang_info['script']})\", lang) \n",
    "                    for lang, lang_info in Config.LANGUAGE_MAPPINGS.items()],\n",
    "            description='Language:',\n",
    "            style={'description_width': 'initial'},\n",
    "            layout=widgets.Layout(width='300px')\n",
    "        )\n",
    "        \n",
    "        # Create a custom HTML input for better Unicode support\n",
    "        self.word_input_html = widgets.HTML(\n",
    "            value='''\n",
    "            <input type=\"text\" id=\"unicode-input\" \n",
    "                placeholder=\"Type a word or phrase...\" \n",
    "                style=\"width: 400px; height: 30px; padding: 5px; border: 1px solid #ccc; border-radius: 3px;\"\n",
    "                onchange=\"window.unicodeInputValue = this.value;\">\n",
    "            ''',\n",
    "            layout=widgets.Layout(width='420px')\n",
    "        )\n",
    "        \n",
    "        # Create a hidden text widget to store the value\n",
    "        self.word_input = widgets.Text(\n",
    "            value='',\n",
    "            disabled=True,\n",
    "            layout=widgets.Layout(display='none')\n",
    "        )\n",
    "        \n",
    "        # Add JavaScript to sync the HTML input with the hidden widget\n",
    "        display(HTML('''\n",
    "        <script>\n",
    "        document.getElementById('unicode-input').addEventListener('input', function() {\n",
    "            window.unicodeInputValue = this.value;\n",
    "        });\n",
    "        </script>\n",
    "        '''))\n",
    "        \n",
    "        # Learn button\n",
    "        self.learn_button = widgets.Button(\n",
    "            description='Learn Word',\n",
    "            button_style='primary',\n",
    "            layout=widgets.Layout(width='150px')\n",
    "        )\n",
    "        self.learn_button.on_click(self.learn_word)\n",
    "        \n",
    "        # Quiz button\n",
    "        self.quiz_button = widgets.Button(\n",
    "            description='Start Quiz',\n",
    "            button_style='success',\n",
    "            layout=widgets.Layout(width='150px')\n",
    "        )\n",
    "        self.quiz_button.on_click(self.start_quiz)\n",
    "        \n",
    "        # Search button\n",
    "        self.search_button = widgets.Button(\n",
    "            description='Search Words',\n",
    "            button_style='info',\n",
    "            layout=widgets.Layout(width='150px')\n",
    "        )\n",
    "        self.search_button.on_click(self.search_words)\n",
    "        \n",
    "        # Progress display\n",
    "        self.progress_output = widgets.Output()\n",
    "        \n",
    "        # Results display\n",
    "        self.results_output = widgets.Output()\n",
    "        \n",
    "        # Status display\n",
    "        self.status_output = widgets.Output()\n",
    "            \n",
    "        \n",
    "    def setup_layout(self):\n",
    "        \"\"\"Setup the layout of widgets\"\"\"\n",
    "        \n",
    "        # Header\n",
    "        header = widgets.HTML(\n",
    "            value=\"<h1>üåç Multilingual Learning Assistant</h1><p>Learn words from Indian languages with AI-powered explanations</p>\",\n",
    "            layout=widgets.Layout(margin='10px 0px')\n",
    "        )\n",
    "        \n",
    "        # Input section\n",
    "        input_section = widgets.VBox([\n",
    "            widgets.HBox([self.language_dropdown, self.word_input]),\n",
    "            widgets.HBox([self.learn_button, self.quiz_button, self.search_button])\n",
    "        ])\n",
    "        \n",
    "        # Display section\n",
    "        display_section = widgets.VBox([\n",
    "            self.status_output,\n",
    "            self.progress_output,\n",
    "            self.results_output\n",
    "        ])\n",
    "        \n",
    "        # Main layout\n",
    "        self.main_layout = widgets.VBox([\n",
    "            header,\n",
    "            input_section,\n",
    "            display_section\n",
    "        ])\n",
    "    \n",
    "    def display(self):\n",
    "        \"\"\"Display the interface\"\"\"\n",
    "        display(self.main_layout)\n",
    "    \n",
    "    def update_status(self, message: str, status_type: str = 'info'):\n",
    "        \"\"\"Update status display\"\"\"\n",
    "        with self.status_output:\n",
    "            clear_output(wait=True)\n",
    "            if status_type == 'error':\n",
    "                display(HTML(f\"<p style='color: red;'>{message}</p>\"))\n",
    "            elif status_type == 'success':\n",
    "                display(HTML(f\"<p style='color: green;'>{message}</p>\"))\n",
    "            else:\n",
    "                display(HTML(f\"<p style='color: blue;'>{message}</p>\"))\n",
    "    \n",
    "    def learn_word(self, button):\n",
    "        \"\"\"Process word learning workflow\"\"\"\n",
    "        with self.progress_output:\n",
    "            clear_output(wait=True)\n",
    "            display(HTML(\"<p>üîÑ Processing word...</p>\"))\n",
    "        \n",
    "        try:\n",
    "            # Get inputs\n",
    "            language = self.language_dropdown.value\n",
    "            word = self.word_input.value.strip()\n",
    "            \n",
    "            if not language or not word:\n",
    "                self.update_status(\"Please select a language and enter a word\", 'error')\n",
    "                return\n",
    "            \n",
    "            # Step 1: Translate\n",
    "            self.update_status(\"Translating word to English...\")\n",
    "            translation_result = translation_service.translate_to_english(word, language)\n",
    "            \n",
    "            if translation_result['error']:\n",
    "                self.update_status(f\"Translation failed: {translation_result['error']}\", 'error')\n",
    "                return\n",
    "            \n",
    "            # Step 2: Get Gemma explanation\n",
    "            self.update_status(\"Getting AI explanation...\")\n",
    "            explanation_result = gemma_service.get_word_explanation(\n",
    "                word, language, translation_result['translated_text']\n",
    "            )\n",
    "            \n",
    "            # Step 3: Store word\n",
    "            self.update_status(\"Saving word to database...\")\n",
    "            word_data = {\n",
    "                'original_word': word,\n",
    "                'english_translation': translation_result['translated_text'],\n",
    "                'language': language,\n",
    "                'pronunciation': explanation_result['pronunciation'],\n",
    "                'usage_examples': explanation_result['usage_examples'],\n",
    "                'cultural_context': explanation_result['cultural_context'],\n",
    "                'related_words': explanation_result['related_words'],\n",
    "                'translation_confidence': translation_result['confidence'],\n",
    "                'model_used': translation_result['model_used']\n",
    "            }\n",
    "            \n",
    "            success = storage_service.add_word(word_data)\n",
    "            \n",
    "            if success:\n",
    "                # Display results\n",
    "                with self.results_output:\n",
    "                    clear_output(wait=True)\n",
    "                    \n",
    "                    html_content = f\"\"\"\n",
    "                    <div style='border: 2px solid #4CAF50; padding: 15px; border-radius: 10px; margin: 10px 0;'>\n",
    "                        <h3>‚úÖ Word Learned Successfully!</h3>\n",
    "                        <p><strong>Original:</strong> {word} ({Config.LANGUAGE_MAPPINGS[language]['name']})</p>\n",
    "                        <p><strong>Translation:</strong> {translation_result['translated_text']}</p>\n",
    "                        <p><strong>Pronunciation:</strong> {explanation_result['pronunciation']}</p>\n",
    "                        \n",
    "                        <h4>Usage Examples:</h4>\n",
    "                        <ul>\n",
    "                    \"\"\"\n",
    "                    \n",
    "                    for example in explanation_result['usage_examples'][:3]:\n",
    "                        html_content += f\"<li>{example}</li>\"\n",
    "                    \n",
    "                    html_content += f\"\"\"\n",
    "                        </ul>\n",
    "                        \n",
    "                        <h4>Cultural Context:</h4>\n",
    "                        <p>{explanation_result['cultural_context']}</p>\n",
    "                        \n",
    "                        <h4>Related Words:</h4>\n",
    "                        <ul>\n",
    "                    \"\"\"\n",
    "                    \n",
    "                    for related in explanation_result['related_words'][:3]:\n",
    "                        html_content += f\"<li>{related}</li>\"\n",
    "                    \n",
    "                    html_content += \"\"\"\n",
    "                        </ul>\n",
    "                    </div>\n",
    "                    \"\"\"\n",
    "                    \n",
    "                    display(HTML(html_content))\n",
    "                \n",
    "                self.update_status(f\"Successfully learned '{word}' from {Config.LANGUAGE_MAPPINGS[language]['name']}!\", 'success')\n",
    "                self.word_input.value = ''  # Clear input\n",
    "            else:\n",
    "                self.update_status(\"Failed to save word\", 'error')\n",
    "                \n",
    "        except Exception as e:\n",
    "            self.update_status(f\"Error: {str(e)}\", 'error')\n",
    "    \n",
    "    def start_quiz(self, button):\n",
    "        \"\"\"Start quiz mode\"\"\"\n",
    "        quiz_words = storage_service.get_random_words_for_quiz(5)\n",
    "        \n",
    "        if not quiz_words:\n",
    "            self.update_status(\"No words available for quiz. Learn some words first!\", 'error')\n",
    "            return\n",
    "        \n",
    "        self.run_quiz(quiz_words)\n",
    "    \n",
    "    def run_quiz(self, quiz_words: List[Dict[str, Any]]):\n",
    "        \"\"\"Run the quiz interface\"\"\"\n",
    "        with self.results_output:\n",
    "            clear_output(wait=True)\n",
    "            \n",
    "            html_content = \"<h3>üß† Quiz Mode</h3>\"\n",
    "            \n",
    "            for i, word in enumerate(quiz_words, 1):\n",
    "                html_content += f\"\"\"\n",
    "                <div style='border: 1px solid #ddd; padding: 10px; margin: 10px 0; border-radius: 5px;'>\n",
    "                    <h4>Question {i}:</h4>\n",
    "                    <p><strong>Word:</strong> {word['original_word']} ({word['language']})</p>\n",
    "                    <p><strong>What does this word mean in English?</strong></p>\n",
    "                    <details>\n",
    "                        <summary>Click to see answer</summary>\n",
    "                        <p><strong>Answer:</strong> {word['english_translation']}</p>\n",
    "                        <p><strong>Pronunciation:</strong> {word['pronunciation']}</p>\n",
    "                        <p><strong>Cultural Context:</strong> {word['cultural_context']}</p>\n",
    "                    </details>\n",
    "                </div>\n",
    "                \"\"\"\n",
    "            \n",
    "            display(HTML(html_content))\n",
    "        \n",
    "        self.update_status(f\"Quiz completed! Tested {len(quiz_words)} words.\", 'success')\n",
    "    \n",
    "    def search_words(self, button):\n",
    "        \"\"\"Search existing words\"\"\"\n",
    "        search_query = self.word_input.value.strip()\n",
    "        \n",
    "        if not search_query:\n",
    "            self.update_status(\"Please enter a search term\", 'error')\n",
    "            return\n",
    "        \n",
    "        results = storage_service.search_words(search_query, 10)\n",
    "        \n",
    "        with self.results_output:\n",
    "            clear_output(wait=True)\n",
    "            \n",
    "            if results:\n",
    "                html_content = f\"<h3>ÔøΩÔøΩ Search Results for '{search_query}'</h3>\"\n",
    "                \n",
    "                for word in results:\n",
    "                    html_content += f\"\"\"\n",
    "                    <div style='border: 1px solid #ddd; padding: 10px; margin: 10px 0; border-radius: 5px;'>\n",
    "                        <p><strong>{word['original_word']}</strong> ({word['language']})</p>\n",
    "                        <p><strong>Translation:</strong> {word['english_translation']}</p>\n",
    "                        <p><strong>Similarity Score:</strong> {word['similarity_score']:.2f}</p>\n",
    "                        <p><strong>Added:</strong> {word['date_added'][:10]}</p>\n",
    "                    </div>\n",
    "                    \"\"\"\n",
    "                \n",
    "                display(HTML(html_content))\n",
    "                self.update_status(f\"Found {len(results)} similar words\", 'success')\n",
    "            else:\n",
    "                display(HTML(\"<p>No words found matching your search.</p>\"))\n",
    "                self.update_status(\"No results found\", 'info')\n",
    "\n",
    "# Initialize and display the interface\n",
    "interface = MultilingualLearningInterface()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2815660b",
   "metadata": {},
   "source": [
    "Block 7: Initialize and Display Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "768b2be8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7054f558ca85478e89d99bcb93d87dbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h1>üåç Multilingual Learning Assistant</h1><p>Learn words from Indian languages with‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "üöÄ Multilingual Learning Assistant Ready!\n",
      "============================================================\n",
      "üìö Total words learned: 14\n",
      "üåç Supported languages: 16\n",
      "ÔøΩÔøΩ Translation models: ‚úÖ\n",
      "üß† Gemma model: ‚úÖ\n",
      "üíæ Storage: ‚úÖ\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Initialize and Display Interface\n",
    "# Display the main interface\n",
    "interface.display()\n",
    "\n",
    "# Show system status\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üöÄ Multilingual Learning Assistant Ready!\")\n",
    "print(\"=\"*60)\n",
    "print(f\"üìö Total words learned: {len(storage_service.get_all_words())}\")\n",
    "print(f\"üåç Supported languages: {len(Config.LANGUAGE_MAPPINGS)}\")\n",
    "print(f\"ÔøΩÔøΩ Translation models: {'‚úÖ' if translation_service.translator else '‚ùå'}\")\n",
    "print(f\"üß† Gemma model: {'‚úÖ' if gemma_service.model else '‚ùå'}\")\n",
    "print(f\"üíæ Storage: {'‚úÖ' if storage_service.index else '‚ùå'}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b0ff51e",
   "metadata": {},
   "source": [
    "Block 8: Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "63e030e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Utility Functions\n",
    "def export_learned_words(filename: str = None):\n",
    "    \"\"\"Export all learned words to CSV\"\"\"\n",
    "    if filename is None:\n",
    "        filename = f\"learned_words_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\"\n",
    "    \n",
    "    words = storage_service.get_all_words()\n",
    "    if words:\n",
    "        df = pd.DataFrame(words)\n",
    "        df.to_csv(filename, index=False, encoding='utf-8')\n",
    "        print(f\"‚úÖ Exported {len(words)} words to {filename}\")\n",
    "    else:\n",
    "        print(\"‚ùå No words to export\")\n",
    "\n",
    "def get_language_statistics():\n",
    "    \"\"\"Get statistics by language\"\"\"\n",
    "    words = storage_service.get_all_words()\n",
    "    if words:\n",
    "        df = pd.DataFrame(words)\n",
    "        stats = df['language'].value_counts()\n",
    "        print(\"\\nüìä Language Statistics:\")\n",
    "        for lang, count in stats.items():\n",
    "            print(f\"  {lang}: {count} words\")\n",
    "    else:\n",
    "        print(\"‚ùå No words found\")\n",
    "\n",
    "def clear_all_data():\n",
    "    \"\"\"Clear all stored data (use with caution!)\"\"\"\n",
    "    confirm = input(\"Are you sure you want to delete all learned words? (yes/no): \")\n",
    "    if confirm.lower() == 'yes':\n",
    "        try:\n",
    "            os.remove(Config.FAISS_INDEX_PATH)\n",
    "            os.remove(Config.METADATA_PATH)\n",
    "            storage_service.metadata = []\n",
    "            storage_service.index = None\n",
    "            print(\"‚úÖ All data cleared\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error clearing data: {e}\")\n",
    "    else:\n",
    "        print(\"‚ùå Operation cancelled\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47fd94fc",
   "metadata": {},
   "source": [
    "Block 9: Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4292a96f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "COMPREHENSIVE FEATURE TESTING\n",
      "============================================================\n",
      "\n",
      "1. TESTING TRANSLATION SERVICE\n",
      "------------------------------\n",
      "PASS: Translation service working\n",
      "   Input: ‡§®‡§Æ‡§∏‡•ç‡§§‡•á\n",
      "   Output: Hello.\n",
      "\n",
      "2. TESTING GEMMA EXPLANATION SERVICE\n",
      "------------------------------\n",
      "PASS: Gemma explanation service working\n",
      "   Pronunciation: unknown\n",
      "   Examples: 0 found\n",
      "\n",
      "3. TESTING STORAGE SERVICE\n",
      "------------------------------\n",
      "‚úÖ Added word: ‡§®‡§Æ‡§∏‡•ç‡§§‡•á (hindi)\n",
      "PASS: Storage service working\n",
      "   Words stored: 15\n",
      "\n",
      "4. TESTING SEARCH SERVICE\n",
      "------------------------------\n",
      "PASS: Search service working\n",
      "   Search results: 5 found\n",
      "\n",
      "5. TESTING QUIZ SERVICE\n",
      "------------------------------\n",
      "PASS: Quiz service working\n",
      "   Quiz words available: 3\n",
      "\n",
      "6. TESTING INTERFACE COMPONENTS\n",
      "------------------------------\n",
      "PASS: Interface components working\n",
      "   Dropdown: Created successfully\n",
      "   Text input: Created successfully\n",
      "   Button: Created successfully\n",
      "\n",
      "7. TESTING LANGUAGE SUPPORT\n",
      "------------------------------\n",
      "PASS: Language support working\n",
      "   Supported languages: 16\n",
      "   Sample languages: ['hindi', 'tamil', 'bengali', 'kannada', 'telugu']\n",
      "\n",
      "8. TESTING CONFIGURATION\n",
      "------------------------------\n",
      "PASS: Configuration working\n",
      "   Hugging Face token: Set\n",
      "   Google AI key: Set\n",
      "   Translation model: Helsinki-NLP/opus-mt-hi-en\n",
      "\n",
      "============================================================\n",
      "TESTING SUMMARY\n",
      "============================================================\n",
      "TRANSLATION: PASS\n",
      "GEMMA_EXPLANATION: PASS\n",
      "STORAGE: PASS\n",
      "SEARCH: PASS\n",
      "QUIZ: PASS\n",
      "INTERFACE: PASS\n",
      "\n",
      "OVERALL: 6/6 features working\n",
      "STATUS: All features working correctly!\n"
     ]
    }
   ],
   "source": [
    "# Cell: Comprehensive Feature Testing\n",
    "def test_all_features():\n",
    "    \"\"\"Test all features of the Multilingual Learning Assistant\"\"\"\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"COMPREHENSIVE FEATURE TESTING\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    test_results = {\n",
    "        'translation': False,\n",
    "        'gemma_explanation': False,\n",
    "        'storage': False,\n",
    "        'search': False,\n",
    "        'quiz': False,\n",
    "        'interface': False\n",
    "    }\n",
    "    \n",
    "    # Test 1: Translation Service\n",
    "    print(\"\\n1. TESTING TRANSLATION SERVICE\")\n",
    "    print(\"-\" * 30)\n",
    "    try:\n",
    "        test_word = \"‡§®‡§Æ‡§∏‡•ç‡§§‡•á\"  # Hello in Hindi\n",
    "        result = translation_service.translate_to_english(test_word, \"hindi\")\n",
    "        \n",
    "        if result['error'] is None and result['translated_text'] != 'unknown':\n",
    "            print(\"PASS: Translation service working\")\n",
    "            print(f\"   Input: {result['original_text']}\")\n",
    "            print(f\"   Output: {result['translated_text']}\")\n",
    "            test_results['translation'] = True\n",
    "        else:\n",
    "            print(\"FAIL: Translation service error\")\n",
    "            print(f\"   Error: {result['error']}\")\n",
    "    except Exception as e:\n",
    "        print(f\"FAIL: Translation service exception - {e}\")\n",
    "    \n",
    "    # Test 2: Gemma Explanation Service\n",
    "    print(\"\\n2. TESTING GEMMA EXPLANATION SERVICE\")\n",
    "    print(\"-\" * 30)\n",
    "    try:\n",
    "        explanation = gemma_service.get_word_explanation(\"‡§®‡§Æ‡§∏‡•ç‡§§‡•á\", \"hindi\", \"Hello\")\n",
    "        \n",
    "        if explanation['error'] is None:\n",
    "            print(\"PASS: Gemma explanation service working\")\n",
    "            print(f\"   Pronunciation: {explanation['pronunciation']}\")\n",
    "            print(f\"   Examples: {len(explanation['usage_examples'])} found\")\n",
    "            test_results['gemma_explanation'] = True\n",
    "        else:\n",
    "            print(\"FAIL: Gemma explanation service error\")\n",
    "            print(f\"   Error: {explanation['error']}\")\n",
    "    except Exception as e:\n",
    "        print(f\"FAIL: Gemma explanation service exception - {e}\")\n",
    "    \n",
    "    # Test 3: Storage Service\n",
    "    print(\"\\n3. TESTING STORAGE SERVICE\")\n",
    "    print(\"-\" * 30)\n",
    "    try:\n",
    "        # Test adding a word\n",
    "        test_word_data = {\n",
    "            'original_word': '‡§®‡§Æ‡§∏‡•ç‡§§‡•á',\n",
    "            'english_translation': 'Hello',\n",
    "            'language': 'hindi',\n",
    "            'pronunciation': 'namaste',\n",
    "            'usage_examples': ['‡§®‡§Æ‡§∏‡•ç‡§§‡•á, ‡§ï‡•à‡§∏‡•á ‡§π‡•ã?'],\n",
    "            'cultural_context': 'Traditional greeting',\n",
    "            'related_words': ['‡§™‡•ç‡§∞‡§£‡§æ‡§Æ', '‡§∏‡•ç‡§µ‡§æ‡§ó‡§§'],\n",
    "            'translation_confidence': 0.8,\n",
    "            'model_used': 'test'\n",
    "        }\n",
    "        \n",
    "        success = storage_service.add_word(test_word_data)\n",
    "        if success:\n",
    "            print(\"PASS: Storage service working\")\n",
    "            print(f\"   Words stored: {len(storage_service.get_all_words())}\")\n",
    "            test_results['storage'] = True\n",
    "        else:\n",
    "            print(\"FAIL: Storage service failed to add word\")\n",
    "    except Exception as e:\n",
    "        print(f\"FAIL: Storage service exception - {e}\")\n",
    "    \n",
    "    # Test 4: Search Service\n",
    "    print(\"\\n4. TESTING SEARCH SERVICE\")\n",
    "    print(\"-\" * 30)\n",
    "    try:\n",
    "        search_results = storage_service.search_words(\"hello\", 5)\n",
    "        \n",
    "        if isinstance(search_results, list):\n",
    "            print(\"PASS: Search service working\")\n",
    "            print(f\"   Search results: {len(search_results)} found\")\n",
    "            test_results['search'] = True\n",
    "        else:\n",
    "            print(\"FAIL: Search service returned invalid results\")\n",
    "    except Exception as e:\n",
    "        print(f\"FAIL: Search service exception - {e}\")\n",
    "    \n",
    "    # Test 5: Quiz Service\n",
    "    print(\"\\n5. TESTING QUIZ SERVICE\")\n",
    "    print(\"-\" * 30)\n",
    "    try:\n",
    "        quiz_words = storage_service.get_random_words_for_quiz(3)\n",
    "        \n",
    "        if isinstance(quiz_words, list):\n",
    "            print(\"PASS: Quiz service working\")\n",
    "            print(f\"   Quiz words available: {len(quiz_words)}\")\n",
    "            test_results['quiz'] = True\n",
    "        else:\n",
    "            print(\"FAIL: Quiz service returned invalid results\")\n",
    "    except Exception as e:\n",
    "        print(f\"FAIL: Quiz service exception - {e}\")\n",
    "    \n",
    "    # Test 6: Interface Components\n",
    "    print(\"\\n6. TESTING INTERFACE COMPONENTS\")\n",
    "    print(\"-\" * 30)\n",
    "    try:\n",
    "        # Test if interface components can be created\n",
    "        from ipywidgets import Dropdown, Text, Button\n",
    "        \n",
    "        test_dropdown = Dropdown(options=[('Hindi', 'hindi')])\n",
    "        test_input = Text(placeholder='Test input')\n",
    "        test_button = Button(description='Test')\n",
    "        \n",
    "        print(\"PASS: Interface components working\")\n",
    "        print(\"   Dropdown: Created successfully\")\n",
    "        print(\"   Text input: Created successfully\")\n",
    "        print(\"   Button: Created successfully\")\n",
    "        test_results['interface'] = True\n",
    "    except Exception as e:\n",
    "        print(f\"FAIL: Interface components exception - {e}\")\n",
    "    \n",
    "    # Test 7: Language Support\n",
    "    print(\"\\n7. TESTING LANGUAGE SUPPORT\")\n",
    "    print(\"-\" * 30)\n",
    "    try:\n",
    "        supported_languages = list(Config.LANGUAGE_MAPPINGS.keys())\n",
    "        print(f\"PASS: Language support working\")\n",
    "        print(f\"   Supported languages: {len(supported_languages)}\")\n",
    "        print(f\"   Sample languages: {supported_languages[:5]}\")\n",
    "    except Exception as e:\n",
    "        print(f\"FAIL: Language support exception - {e}\")\n",
    "    \n",
    "    # Test 8: Configuration\n",
    "    print(\"\\n8. TESTING CONFIGURATION\")\n",
    "    print(\"-\" * 30)\n",
    "    try:\n",
    "        print(\"PASS: Configuration working\")\n",
    "        print(f\"   Hugging Face token: {'Set' if Config.HUGGINGFACE_TOKEN else 'Not set'}\")\n",
    "        print(f\"   Google AI key: {'Set' if Config.GOOGLE_AI_KEY else 'Not set'}\")\n",
    "        print(f\"   Translation model: {Config.DEFAULT_TRANSLATION_MODEL}\")\n",
    "    except Exception as e:\n",
    "        print(f\"FAIL: Configuration exception - {e}\")\n",
    "    \n",
    "    # Summary\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"TESTING SUMMARY\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    passed_tests = sum(test_results.values())\n",
    "    total_tests = len(test_results)\n",
    "    \n",
    "    for feature, result in test_results.items():\n",
    "        status = \"PASS\" if result else \"FAIL\"\n",
    "        print(f\"{feature.upper()}: {status}\")\n",
    "    \n",
    "    print(f\"\\nOVERALL: {passed_tests}/{total_tests} features working\")\n",
    "    \n",
    "    if passed_tests == total_tests:\n",
    "        print(\"STATUS: All features working correctly!\")\n",
    "    elif passed_tests >= total_tests * 0.7:\n",
    "        print(\"STATUS: Most features working, minor issues detected\")\n",
    "    else:\n",
    "        print(\"STATUS: Multiple features need attention\")\n",
    "    \n",
    "    return test_results\n",
    "\n",
    "# Run the comprehensive test\n",
    "test_results = test_all_features()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
